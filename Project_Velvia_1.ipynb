{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageEnhance\n",
    "import numpy as np \n",
    "import os\n",
    "import cv2\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, xyz2lab\n",
    "from skimage.io import imsave\n",
    "# np.save('example_1', a)\n",
    "# b = np.load('example/example_1.npy')\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "#import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"/Users/alexeyvaganov/doc/files/color_matcher/BW\"\n",
    "image_massiv = \"/Users/alexeyvaganov/doc/files/color_matcher/temp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обходим все файлы в папке Y\n",
    "# Нам надо сделать массив, в котором в кажой строке будет два элемента\n",
    "# в первом элементе массива искомая фотография\n",
    "# во втором элемент массива измененная фотография\n",
    "# из каждой фотографии делаем N измененых фотографий в зависимости от параметров\n",
    "# сохраняем массив на диск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_transform_nastr = [\n",
    "    [1.5,0.5,0.5],\n",
    "    [1.5,1,0.5],\n",
    "    [1,1,0.8],\n",
    "    [1,1,2],\n",
    "    [2,1.2,0],\n",
    "    [2,1.2,0.1]\n",
    "]\n",
    "\n",
    "# array_transform_nastr = [\n",
    "#     [0.5,0.5,0.5],\n",
    "#     [1.0,1.0,1.0],\n",
    "#     [0.2,0.2,0.2],\n",
    "#     [1,1,2],\n",
    "#     [0.8,1.2,0],\n",
    "#     [2,1.2,0.1]\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img_file):\n",
    "    img = Image.open(img_file)\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(img_pil,brightness,contrast,color):\n",
    "    if (brightness != 0):\n",
    "        enhancer = ImageEnhance.Brightness(img_pil)\n",
    "        img_pil = enhancer.enhance(brightness)\n",
    "    if (contrast != 0):\n",
    "        enhancer = ImageEnhance.Contrast(img_pil)\n",
    "        img_pil = enhancer.enhance(contrast)\n",
    "    if (color != 0):\n",
    "        enhancer = ImageEnhance.Color(img_pil)\n",
    "        img_pil = enhancer.enhance(color) \n",
    "    return img_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 2, 960, 1440, 3)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_image = []\n",
    "for root, dirs, files in os.walk(image_folder):\n",
    "    for file in files:\n",
    "        if file == \".DS_Store\":\n",
    "            continue\n",
    "        img_pil = Image.open(root + \"/\" + file)\n",
    "        img_pil = img_pil.convert('RGB')\n",
    "        img_pil_lab = rgb2lab(img_pil)\n",
    "        #img_cv2_ish = cv2.imread(root + \"/\" + file)\n",
    "        for x in array_transform_nastr:\n",
    "            img_ = transform_image(img_pil,x[0],x[1],x[2])\n",
    "            #img_.save(\"/Users/alexeyvaganov/doc/files/color_matcher/temp/geeks.jpg\")\n",
    "            #img_cv2_transf = cv2.imread(\"/Users/alexeyvaganov/doc/files/color_matcher/temp/geeks.jpg\")\n",
    "            img_lab = rgb2lab(img_)\n",
    "            #img_pil = rgb2lab(img_pil)\n",
    "            array_image.append([np.array(img_lab),np.array(img_pil_lab)])\n",
    "        \n",
    "array_full_image = np.array(array_image) \n",
    "array_full_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "#img_show = array_full_image[0,0]\n",
    "#imsave(\"/Users/alexeyvaganov/doc/files/color_matcher/temp/geeks.jpg\", lab2rgb(array_full_image[1,0]))\n",
    "#img_show.save(\"/Users/alexeyvaganov/doc/files/color_matcher/temp/geeks.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savez_compressed(image_massiv, a=np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the neural network\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(None, None, 2)))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "#model.compile(optimizer='rmsprop', loss='mse', metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "#model.compile(optimizer='rmsprop', loss='mse')\n",
    "model.compile(optimizer='Adadelta', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: /Users/alexeyvaganov/doc/files/color_matcher/temp/geeks.jpg is a low contrast image\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "#imsave(\"/Users/alexeyvaganov/doc/files/color_matcher/temp/geeks.jpg\", np_array_x_y[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(array_x_y,a,b):\n",
    "    h=0\n",
    "    while h <= a.shape[0]-56:\n",
    "        w=0\n",
    "        while w <= a.shape[1]-56:\n",
    "            x_ = a[h:h+56,w:w+56]\n",
    "            y_ = b[h:h+56,w:w+56]\n",
    "            array_x_y.append([x_,y_])\n",
    "            w+=56\n",
    "        h+=56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7650, 2, 56, 56, 3)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_x_y = []\n",
    "i=0\n",
    "x_sgape = array_full_image.shape[0]\n",
    "while i < x_sgape:\n",
    "    crop_image(array_x_y,array_full_image[i,0],array_full_image[i,1])\n",
    "    i+=1\n",
    "array_crop_image = np.array(array_x_y) \n",
    "array_crop_image = 1.0/255*array_crop_image\n",
    "array_crop_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = array_crop_image[:,0]\n",
    "Y_ = array_crop_image[:,1]\n",
    "X_ = X_[:,:,:,1:]\n",
    "Y_ = Y_[:,:,:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(image_massiv + 'Velvia_19_8_15.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "240/240 [==============================] - 41s 165ms/step - loss: 3.1244e-05\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 40s 168ms/step - loss: 2.4977e-05\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 53s 219ms/step - loss: 2.1021e-05\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 47s 195ms/step - loss: 1.8182e-05\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 55s 227ms/step - loss: 1.6248e-05\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 43s 180ms/step - loss: 1.4887e-05\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 50s 210ms/step - loss: 1.4043e-05\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 45s 185ms/step - loss: 1.3448e-05\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 41s 171ms/step - loss: 1.3273e-05\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 42s 174ms/step - loss: 1.3069e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb182e798d0>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_,Y_,batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "Obr = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3088, 2316, 3)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#array_img_test = []\n",
    "file_name = \"IMG_2269.jpg\"\n",
    "test_image_path = image_massiv + file_name\n",
    "img_test = Image.open(test_image_path)\n",
    "img_test = img_test.convert('RGB')\n",
    "#array_img_test.append(img_test) \n",
    "img_test = rgb2lab(img_test)\n",
    "array_full_img_test = np.array(img_test) \n",
    "array_full_img_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = np.zeros((array_full_img_test.shape[0], array_full_img_test.shape[1], 3))\n",
    "h=0\n",
    "while h <= array_full_img_test.shape[0]-56:\n",
    "    w=0\n",
    "    while w <= array_full_img_test.shape[1]-56:\n",
    "        # predict\n",
    "        x_iz = array_full_img_test[h:h+56,w:w+56]\n",
    "        x_ = x_iz[:,:,1:]\n",
    "        x_ = 1.0/255*x_\n",
    "        x_ = x_.reshape(1,56,56,2)\n",
    "        pred_y = model.predict(x_)\n",
    "        \n",
    "        cur = np.zeros((56, 56, 3))\n",
    "        cur[:,:,0] = x_iz[:,:,0]\n",
    "        pred_y = pred_y[0]* 256\n",
    "        cur[:,:,1:] = pred_y\n",
    "        \n",
    "        new_img[h:h+56,w:w+56] = cur\n",
    "        \n",
    "        w+=56\n",
    "    h+=56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "imsave(image_massiv + str(Obr) + file_name, lab2rgb(new_img))\n",
    "Obr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(image_massiv + Velvia_19_8_4.h5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прочее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred = array_full_img_test[0:56,0:56]\n",
    "img_pred_col = img_pred[:,:,1:]\n",
    "img_pred_col = 1.0/255*img_pred_col\n",
    "img_pred_col = img_pred_col.reshape(1,56,56,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 56, 1)\n",
      "[[[87.62802886]\n",
      "  [87.62802886]\n",
      "  [87.27331251]\n",
      "  ...\n",
      "  [87.62802886]\n",
      "  [87.68525276]\n",
      "  [87.50052494]]\n",
      "\n",
      " [[67.2156848 ]\n",
      "  [66.84179228]\n",
      "  [66.84179228]\n",
      "  ...\n",
      "  [68.50146286]\n",
      "  [68.56967781]\n",
      "  [68.56967781]]\n",
      "\n",
      " [[67.18258232]\n",
      "  [67.18258232]\n",
      "  [67.18258232]\n",
      "  ...\n",
      "  [68.59121952]\n",
      "  [68.59121952]\n",
      "  [68.59121952]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[70.22792326]\n",
      "  [70.22792326]\n",
      "  [70.59680428]\n",
      "  ...\n",
      "  [71.52757235]\n",
      "  [71.52757235]\n",
      "  [71.52757235]]\n",
      "\n",
      " [[70.22792326]\n",
      "  [70.22792326]\n",
      "  [70.59680428]\n",
      "  ...\n",
      "  [71.52757235]\n",
      "  [71.52757235]\n",
      "  [71.52757235]]\n",
      "\n",
      " [[70.22792326]\n",
      "  [70.22792326]\n",
      "  [70.59680428]\n",
      "  ...\n",
      "  [71.52757235]\n",
      "  [71.52757235]\n",
      "  [71.52757235]]]\n"
     ]
    }
   ],
   "source": [
    "img_lab = img_pred[:,:,:1]\n",
    "print (img_lab.shape)\n",
    "print (img_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_mod = model.predict(img_pred_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pr_mod_f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-707e15beb78d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpr_mod_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_lab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pr_mod_f' is not defined"
     ]
    }
   ],
   "source": [
    "print(pr_mod_f[0].shape)\n",
    "print(img_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = np.zeros((56, 56, 3))\n",
    "cur[:,:,0] = img_pred[:,:,0]\n",
    "prrr = pr_mod[0]* 256\n",
    "cur[:,:,1:] = prrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([208.        , 157.64634705, 180.79605103])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 56, 2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_mod_f = pr_mod * 256\n",
    "it_img = pr_mod_f[0][:,:,] + img_lab[:,:,]\n",
    "it_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_img = np.zeros((array_full_img_test.shape[0], array_full_img_test.shape[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(X)\n",
    "output *= 128\n",
    "# Output colorizations\n",
    "cur = np.zeros((400, 400, 3))\n",
    "cur[:,:,0] = X[0][:,:,0]\n",
    "cur[:,:,1:] = output[0]\n",
    "imsave(\"img_result.png\", lab2rgb(cur))\n",
    "imsave(\"img_gray_version.png\", rgb2gray(lab2rgb(cur)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transformer\n",
    "batch_size = 10\n",
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=20,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90972, 2, 50, 50, 3)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate training data\n",
    "batch_size = 10\n",
    "def image_a_b_gen(batch_size):\n",
    "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
    "        lab_batch = rgb2lab(batch)\n",
    "        X_batch = lab_batch[:,:,:,0]\n",
    "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model      \n",
    "tensorboard = TensorBoard(log_dir=\"output/first_run\")\n",
    "model.fit_generator(image_a_b_gen(batch_size), callbacks=[tensorboard], epochs=1, steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import map images into the lab colorspace\n",
    "def image_to_lab(image):\n",
    "    X = rgb2lab(1.0/255*image)[:,:,0]\n",
    "    #X = X.reshape(X.shape+(1,))\n",
    "    X = X.reshape(1,50,50,1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "wqw2w = image_to_lab(np_array_x_y[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50, 50, 1)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wqw2w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_x_lab = []\n",
    "array_y_lab = []\n",
    "i = 0\n",
    "#while i < np_array_x_y.shape[0]:\n",
    "while i < 1:\n",
    "    lab_x = image_to_lab(np_array_x_y[i,0])\n",
    "    array_x_lab.append(lab_x)\n",
    "    lab_y = image_to_lab(np_array_x_y[i,1])\n",
    "    array_y_lab.append(lab_y)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array_x_lab[:10]\n",
    "Y = array_y_lab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X) \n",
    "Y = np.array(Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50, 50, 1)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 1), dtype=tf.float32, name='input_7'), name='input_7', description=\"created by layer 'input_7'\"), but it was called on an input with incompatible shape (10, 1, 50, 50).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:784 train_function  *\n        return step_function(self, iterator)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:774 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1261 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2725 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3337 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:767 run_step  **\n        outputs = model.train_step(data)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:733 train_step\n        y_pred = self(x, training=True)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:992 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:375 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:426 call\n        inputs, training=training, mask=mask)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:561 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:979 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:259 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer conv2d_46 is incompatible with the layer: expected axis -1 of input shape to have value 1 but received input with shape (10, 1, 50, 50)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-345-75552d39c0ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     epochs=50)\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1073\u001b[0m                 _r=1):\n\u001b[1;32m   1074\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    819\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2925\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m       (graph_function,\n\u001b[0;32m-> 2927\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2928\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2929\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3350\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3351\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3352\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3354\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3273\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3274\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3275\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3199\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3200\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3202\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    974\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:784 train_function  *\n        return step_function(self, iterator)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:774 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1261 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2725 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3337 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:767 run_step  **\n        outputs = model.train_step(data)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:733 train_step\n        y_pred = self(x, training=True)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:992 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:375 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:426 call\n        inputs, training=training, mask=mask)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:561 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:979 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /Users/alexeyvaganov/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:259 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer conv2d_46 is incompatible with the layer: expected axis -1 of input shape to have value 1 but received input with shape (10, 1, 50, 50)\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=X, \n",
    "    y=Y,\n",
    "    batch_size=10,\n",
    "    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 1)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
