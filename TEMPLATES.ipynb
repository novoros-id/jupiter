{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# определения\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import pickle\n",
    "import pymorphy2\n",
    "import matplotlib.pyplot as plt\n",
    "#import pandas_profiling\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score,classification_report,confusion_matrix,roc_curve,auc,precision_recall_curve,precision_score,recall_score,f1_score,accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "vectorizer = CountVectorizer()\n",
    "plt.style.use('dark_background')\n",
    "# Options for pandas\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.min_rows = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# здесь \"на память\" описываю операторы в одну - две строчки \n",
    "\n",
    "# PANDAS\n",
    "# data.iloc[[0,3,100]] - показать строки по индексу 0,3,100\n",
    "# data.iloc[:,:8] - выбрать первые 8 колонок и все строки\n",
    "# data[data.Survived == 0 ] - отбор по значению\n",
    "# data[data.Survived == 0 ][['Sex','Age']] - отбор  и показать только выбранные колонки\n",
    "# data['new_col'] = data['Survived'] - в новую колонку добавить значение старой колонки\n",
    "# data.rename(columns = {'new_col':'del_col'}) - переименовать колонку\n",
    "# data = data.drop(['new_col'],axis = 'columns') - удалить колонку\n",
    "# del data[\"column\"] - еще один способ удалить колонку\n",
    "# print(data.groupby(['Sex','Survived'])['PassengerId'].count()) - сгруппировать \n",
    "# по колонкам 'Sex','Survived' и подсчету по колонке PassengerId\n",
    "# data.isna().sum() - показать сколько пустых значений в каждой колонке\n",
    "# data.Survived.value_counts() - показать сколько уникальных значений в колонке  Survived\n",
    "# data.Survived.max() - показать максимальное значение в колонке  Survived\n",
    "# data.Survived.nlagerset(3) - показать 3 максимальных  значения в колонке  Survived\n",
    "# data.Survived.idxmax() - показать индекс максимальноого значения в колонке  Survived\n",
    "# data.loc[23] - показать строку 23\n",
    "# data = data.dropna() - удалить все строки с пропусками\n",
    "# data.Sex.replace('male', 0, inplace=True) - заменить значения в колонке Sex: mail - 0\n",
    "# test_out = pd.DataFrame({'PassengerId': test_df.index,'Survived': preds})\n",
    "# создать новый dataframe для выгрузки на кагл\n",
    "# data = pd.read_excel(\"resolution_100.xlsx\") - прочитать файл excel\n",
    "# data.describe() - получаем описание фрэйма, макс, мин, количество и прочее  \n",
    "# data.fillna(method='ffill', inplace=True) - заполнить все пустые предыдущими значениями\n",
    "# data = pandas.get_dummies(data,columns=['columns']) - раскрытие строк через доп. столбцы\n",
    "# data = pd.concat([data_train,data_test]) - объединение таблиц\n",
    "# data = data.assign(type_age=\"\") - добавить колонку\n",
    "# data.loc[1,\"type_age\"] = \"a\" - записать значение в колонку по строке\n",
    "# pd.read_html('http://www.contextures.com/xlSampleData01.html') - на сайте найдет таблицы и считает их\n",
    "\n",
    "# def valuation_formula(x, y): # заполнение ячеек через lambda\n",
    "#   return x * y * 0.5\n",
    "# data['price'] = data.apply(lambda row: valuation_formula(row['x'], row['y']), axis=1)\n",
    "\n",
    "# for idx,row in anime[:2].iterrows(): - обход элементов dataframe\n",
    "#    print(idx, row)\n",
    "# data['price'] = data['price'].apply(функция) - применение функции к столбцу\n",
    "# data.map({'cat': 'kitten', 'dog': 'puppy'}) - замена значений по словарю\n",
    "\n",
    "# sex_stats = df.pivot_table(values='suicides_no', index=['year'], columns=['sex'], aggfunc='mean')\n",
    "# Как и в Excel, здесь есть сводные таблицы (pivot_table). Параметрами метода являются:\n",
    "# values – список переменных, по которым будут считаться статистики,\n",
    "# index – список переменных, по которым нужно сгруппировать данные, будут индексами сводной таблицы,\n",
    "# columns – список переменных, по которым нужно сгруппировать данные, будут столбцами сводной таблицы,\n",
    "# aggfunc — функция аггрегации, т.е. рассчитываемая статистика для данных\n",
    "\n",
    "#PANDAS PROFILING\n",
    "# pandas_profiling.ProfileReport(df)\n",
    "\n",
    "# SEABORN\n",
    "# sns.heatmap(data.corr()) - вывести график корреляций по всем колонкам\n",
    "# sns.boxplot(titanic['age']) - ящик с усами\n",
    "# sns.countplot(x) - строит bar по данным\n",
    "# sns.countplot(x=\"pclass\", data=titanic, hue=\"sex\") - бар по двум колонкам\n",
    "\n",
    "# SKLEARN\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42) \n",
    "# разбить данные на тренировочную и тестовую выборку\n",
    "# 20 процентов на тестовую , случайность выборки зафиксирована\n",
    "# accuracy_score(y_test,y_pred) - коэффециент проверки на проверочной выборке\n",
    "# vectorizer.get_feature_names() - посмотреть словарь векторов текста\n",
    "# чтобы получить сгенерированный словарь, из приведенной структуры CountVectorizer, \n",
    "# стоит отметить что порядок совпадает с матрице\n",
    "# text_vector_array = text_vector.toarray() - покаазть матрицу\n",
    "\n",
    "# kf = KFold(n_splits=5, random_state=1, shuffle=True) подготовка кросс-валидации\n",
    "# model = RandomForestRegressor(random_state=1) объявляем модель\n",
    "# score = np.mean(cross_val_score(estimator=model, X=X, y=y, cv=kf, scoring='r2')) - рассчитываем коэффициент r2\n",
    "\n",
    "# PICKLE\n",
    "# model = pickle.load(open(\"filename\", 'rb')) - загрузка модели из файла\n",
    "# pickle.dump(model, open(\"filename\", 'wb')) - сохрванение модели в файл\n",
    "\n",
    "# MATPLOTLIB\n",
    "# plt.plot(x, y, label='sin') - нарисовать простой график\n",
    "# plt.scatter(x, y, c=colors, s=sizes, alpha=0.5, cmap='plasma',label='sin') - или рисуем точки на графике\n",
    "# plt.grid() - показать сетку\n",
    "# plt.xlabel('Ось x') - название оси Х\n",
    "# plt.colorbar() -  показать легенду цветов, если c=colors\n",
    "# plt.legend() - показать легенду\n",
    "# plt.show() - показать график\n",
    "# plt.savefig('имя_файла') - сохранение графика\n",
    "# plt.hexbin(x, y, cmap='inferno') - тепловая карта\n",
    "# plt.hist(x, color='r', orientation='horizontal') - сторим гистограмму"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# из примера титаник сайта кагл DecisionTreeClassifier\n",
    "# dt = DecisionTreeClassifier(random_state=1)\n",
    "# dt.fit(X_train, y_train)\n",
    "# preds = dt.predict(X_test)\n",
    "# acc = accuracy_score(y_true=y_test, y_pred=preds)\n",
    "# f1 = f1_score(y_true=y_test, y_pred=preds)\n",
    "# print(classification_report(y_true=y_test, y_pred=preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# предсказание простое RandomForestClassifier\n",
    "# clf = RandomForestClassifier(random_state=241)\n",
    "# clf.fit(X, Y)\n",
    "## расчет веса показателей\n",
    "# importances = clf.feature_importances_\n",
    "# print(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# использование GridSearchCV на примере RandomForestClassifier\n",
    "\n",
    "# clf = RandomForestClassifier()\n",
    "\n",
    "# здесь пишем какие параметры будет перебирать\n",
    "\n",
    "# param_greed = {\n",
    "#    \"max_depth\" : [2,5,10],\n",
    "#    \"criterion\" : ['gini', 'entropy'],\n",
    "#    \"min_samples_split\" : [2,5,10],\n",
    "#    \"min_samples_leaf\" : [1,5,10],\n",
    "#}\n",
    "\n",
    "# пишем каие параметры перебираем scoring = как оцениваем  ,\n",
    "# cv = сколько тестовых выборок, n_jobs = -1 используем все процссоры\n",
    "#GS = GridSearchCV(clf,param_greed,scoring = 'roc_auc',cv = 6,n_jobs = -1)\n",
    "#GS.fit(X,Y)\n",
    "\n",
    "# лучший показатель\n",
    "#GS.best_score_\n",
    "\n",
    "# лучшие параметры\n",
    "# GS.best_params_\n",
    "\n",
    "# обращаемся\n",
    "# GS.best_estimator_.feature_importances_\n",
    "\n",
    "# предсказываем\n",
    "# GS.best_estimator_.predict(may_sample_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": [
     0,
     3,
     15,
     40
    ]
   },
   "outputs": [],
   "source": [
    "# универсальные функции\n",
    "\n",
    "# загрузать файл из csv\n",
    "def read_csv(path,index_c = \"\"):\n",
    "    if index_c == \"\":\n",
    "        return pd.read_csv(path)\n",
    "    else:\n",
    "        return pd.read_csv(path,index_col=index_c)\n",
    "    \n",
    "# показать все уникальные значения во всех колонках\n",
    "def columns_unique(data):\n",
    "    for col in data.columns:\n",
    "        print(col, data[col].unique())\n",
    "\n",
    "# заполнить пустые значения средним значением\n",
    "def null_to_mean(data,column):\n",
    "    num_mean = data[column].mean()\n",
    "    data[column].fillna(num_mean, inplace=True)\n",
    "\n",
    "# заполнить пустые значения модой\n",
    "def null_to_mode(data,column):\n",
    "    num_mode  = data[column].mode().values[0]\n",
    "    data[column].fillna(num_mode, inplace=True)\n",
    "\n",
    "# функция для лемматизации\n",
    "def lemmatize(text):\n",
    "    text_str = str(text)\n",
    "    text_str = re.sub(r'[^\\w\\s]+|[\\d]+', r'',text_str).strip()\n",
    "    words = text_str.split() # разбиваем текст на слова\n",
    "    res = \"\"\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        res = res + \" \" + p.normal_form\n",
    "    return res\n",
    "\n",
    "# провести лемматизацию датафрэйм\n",
    "def lemma_dataframe(data,column):\n",
    "    data[column] = data.apply(lambda row: lemmatize(row[column]), axis=1)\n",
    "    \n",
    "# векторизация, создание векторов\n",
    "def vector_text(data,column):\n",
    "    text = data[column]\n",
    "    # создаем векторы\n",
    "    return vectorizer.fit_transform(text)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
