{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37c2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageEnhance\n",
    "import numpy as np \n",
    "import os\n",
    "import cv2\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage import color\n",
    "from skimage.io import imsave\n",
    "# np.save('example_1', a)\n",
    "# b = np.load('example/example_1.npy')\n",
    "# from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose\n",
    "# from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "# from keras.models import Sequential\n",
    "#from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import scale\n",
    "import pickle\n",
    "# import tensorflow as tf\n",
    "# from keras.models import load_model\n",
    "# import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "96412df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(img_pil,brightness,contrast,color):\n",
    "    if (brightness != 0):\n",
    "        enhancer = ImageEnhance.Brightness(img_pil)\n",
    "        img_pil = enhancer.enhance(brightness)\n",
    "    if (contrast != 0):\n",
    "        enhancer = ImageEnhance.Contrast(img_pil)\n",
    "        img_pil = enhancer.enhance(contrast)\n",
    "    if (color != 0):\n",
    "        enhancer = ImageEnhance.Color(img_pil)\n",
    "        img_pil = enhancer.enhance(color) \n",
    "    return img_pil\n",
    "array_transform_nastr = [\n",
    "    [1,1,0.8]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e3daec",
   "metadata": {},
   "source": [
    "# Заполнение идеальных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de20d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(data,a,b):\n",
    "    h=0\n",
    "    while h <= a.shape[0]-pixel:\n",
    "        w=0\n",
    "        while w <= a.shape[1]-pixel:\n",
    "            data.append([a[h,w][1],a[h,w][2],b[h,w][1],b[h,w][2]])\n",
    "            w+=pixel\n",
    "        h+=pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c89435f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/c02w9bp14k1fx5943h90k0500000gn/T/ipykernel_57010/820985584.py:23: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  array_full_image = np.array(array_image)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25, 2)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ИЗ РАЗНЫХ ПАПОК\n",
    "image_folder = \"/Users/alexeyvaganov/doc/files/color_matcher/type\"\n",
    "array_image = []\n",
    "for root, dirs, files in os.walk(image_folder):\n",
    "    for dir_ in dirs:\n",
    "        #print (dir_)\n",
    "        for root_, dirs_, files_ in os.walk(image_folder + \"/\" + dir_):\n",
    "            for file in files_:\n",
    "                if file == \".DS_Store\" or not file[0] == \"_\" or file[1] == \"Y\":\n",
    "                    continue\n",
    "                if file[1] == \"X\":\n",
    "                    #print(file)\n",
    "                    img_X = Image.open(root_ + \"/\" + file)\n",
    "                    img_X = img_X.convert('RGB')\n",
    "                    img_X_lab = rgb2lab(img_X)\n",
    "                    \n",
    "                    img_Y = Image.open(root_ + \"/_Y.jpeg\")\n",
    "                    img_Y = img_Y.convert('RGB')\n",
    "                    img_Y_lab = rgb2lab(img_Y)\n",
    "\n",
    "                    array_image.append([np.array(img_X_lab),np.array(img_Y_lab)])\n",
    "                    \n",
    "array_full_image = np.array(array_image) \n",
    "array_full_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ac43c872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/c02w9bp14k1fx5943h90k0500000gn/T/ipykernel_57010/336729453.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  array_full_image = np.array(array_image)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9, 2)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ИЗ ОДНОЙ ПАПКИ\n",
    "\n",
    "image_folder = \"/Users/alexeyvaganov/doc/files/color_matcher/Portra\"\n",
    "array_image = []\n",
    "for root, dirs, files in os.walk(image_folder):\n",
    "    for file in files:\n",
    "        if file == \".DS_Store\":\n",
    "            continue\n",
    "        img_pil = Image.open(root + \"/\" + file)\n",
    "        img_pil = img_pil.convert('RGB')\n",
    "        img_pil_lab = rgb2lab(img_pil)\n",
    "        #img_cv2_ish = cv2.imread(root + \"/\" + file)\n",
    "        for x in array_transform_nastr:\n",
    "            img_ = transform_image(img_pil,x[0],x[1],x[2])\n",
    "            #img_.save(\"/Users/alexeyvaganov/doc/files/color_matcher/temp/geeks.jpg\")\n",
    "            #img_cv2_transf = cv2.imread(\"/Users/alexeyvaganov/doc/files/color_matcher/temp/geeks.jpg\")\n",
    "            img_lab = rgb2lab(img_)\n",
    "            #img_pil = rgb2lab(img_pil)\n",
    "            array_image.append([np.array(img_lab),np.array(img_pil_lab)])\n",
    "        \n",
    "array_full_image = np.array(array_image) \n",
    "array_full_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ed40e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "i=0\n",
    "x_sgape = array_full_image.shape[0]\n",
    "while i < x_sgape:\n",
    "    crop_image(data,array_full_image[i,0],array_full_image[i,1])\n",
    "    i+=1\n",
    "\n",
    "dFrame = pd.DataFrame(data,columns=['X_a','X_b','Y_a','Y_b']) \n",
    "\n",
    "Slide_ =  dFrame[['Y_a', 'Y_b']]\n",
    "Slide_ = Slide_.drop_duplicates()\n",
    "\n",
    "Slide_.loc[:, 'type'] = \"slide\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2019203f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_a</th>\n",
       "      <th>Y_b</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.895634</td>\n",
       "      <td>-37.474080</td>\n",
       "      <td>slide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.785200</td>\n",
       "      <td>-37.375162</td>\n",
       "      <td>slide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.265667</td>\n",
       "      <td>-36.413036</td>\n",
       "      <td>slide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.763190</td>\n",
       "      <td>-35.076124</td>\n",
       "      <td>slide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.492175</td>\n",
       "      <td>-35.840877</td>\n",
       "      <td>slide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22985943</th>\n",
       "      <td>8.917132</td>\n",
       "      <td>-29.625542</td>\n",
       "      <td>slide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22985944</th>\n",
       "      <td>8.051799</td>\n",
       "      <td>-27.791456</td>\n",
       "      <td>slide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22986328</th>\n",
       "      <td>6.655849</td>\n",
       "      <td>-20.935637</td>\n",
       "      <td>slide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22986719</th>\n",
       "      <td>1.683488</td>\n",
       "      <td>-20.131695</td>\n",
       "      <td>slide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22987096</th>\n",
       "      <td>6.816103</td>\n",
       "      <td>-27.207921</td>\n",
       "      <td>slide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1066293 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Y_a        Y_b   type\n",
       "0         19.895634 -37.474080  slide\n",
       "1         18.785200 -37.375162  slide\n",
       "2         18.265667 -36.413036  slide\n",
       "3         16.763190 -35.076124  slide\n",
       "5         16.492175 -35.840877  slide\n",
       "...             ...        ...    ...\n",
       "22985943   8.917132 -29.625542  slide\n",
       "22985944   8.051799 -27.791456  slide\n",
       "22986328   6.655849 -20.935637  slide\n",
       "22986719   1.683488 -20.131695  slide\n",
       "22987096   6.816103 -27.207921  slide\n",
       "\n",
       "[1066293 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Slide_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0ff719",
   "metadata": {},
   "source": [
    "# Подготовка необработанных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea8602b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = \"/Users/alexeyvaganov/doc/files/color_matcher/temp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "91bf3b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_massiv = []\n",
    "file_name_massiv.append(\"IMG_2825.jpeg\")\n",
    "file_name_massiv.append(\"IMG_3379.jpeg\")\n",
    "file_name_massiv.append(\"IMG_2915.jpeg\")\n",
    "file_name_massiv.append(\"IMG_2980.jpeg\")\n",
    "file_name_massiv.append(\"IMG_3107.jpeg\")\n",
    "file_name_massiv.append(\"IMG_3323.jpeg\")\n",
    "file_name_massiv.append(\"IMG_3336.jpeg\")\n",
    "file_name_massiv.append(\"IMG_2769.jpeg\")\n",
    "file_name_massiv.append(\"IMG_2837.jpeg\")\n",
    "file_name_massiv.append(\"IMG_2847.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27e835c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_testing_file(file_name):\n",
    "    test_image_path = temp_folder + \"/\" + file_name\n",
    "    img_test = Image.open(test_image_path)\n",
    "    img_test = img_test.convert('RGB')\n",
    "    img_test = rgb2lab(img_test)\n",
    "    return np.array(img_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "13d39a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_number_sovpad(ideal, pref):\n",
    "    arrive_testing_file = []\n",
    "    for name_test_file in file_name_massiv:\n",
    "        arr_ = add_testing_file(pref + name_test_file)\n",
    "        arrive_testing_file.append([pref  + name_test_file, arr_])\n",
    "    \n",
    "    Dig_p = []\n",
    "    for m_image in arrive_testing_file:\n",
    "        h=0\n",
    "        while h <= m_image[1].shape[0]-pixel:\n",
    "            w=0\n",
    "            while w <= m_image[1].shape[1]-pixel:\n",
    "                Dig_p.append([m_image[1][h,w][1],m_image[1][h,w][2]])\n",
    "                w+=pixel\n",
    "            h+=pixel \n",
    "\n",
    "    Digital_ = pd.DataFrame(Dig_p,columns=['Y_a','Y_b']) \n",
    "    Digital_ = Digital_.drop_duplicates()\n",
    "    Digital_.loc[:, 'type'] = \"digital\"\n",
    "    \n",
    "    bigdata = pd.concat([ideal,Digital_],ignore_index=True)\n",
    "    \n",
    "    groupideal = ideal.groupby(['Y_a', 'Y_b']).ngroups\n",
    "    groupDigital = Digital_.groupby(['Y_a', 'Y_b']).ngroups\n",
    "    group = bigdata.groupby(['Y_a', 'Y_b']).ngroups\n",
    "    \n",
    "    print (\"for \" + str(pref))\n",
    "    print (\"groupideal \" + str(groupideal))\n",
    "    print (\"groupDigital \" + str(groupDigital))\n",
    "    print (\"group \" + str(group))\n",
    "    \n",
    "    return groupideal + groupDigital - group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b0cee379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for \n",
      "groupideal 1066293\n",
      "groupDigital 560948\n",
      "group 1228118\n",
      "for 57_\n",
      "groupideal 1066293\n",
      "groupDigital 330425\n",
      "group 1115366\n",
      "for 60_\n",
      "groupideal 1066293\n",
      "groupDigital 440190\n",
      "group 1150106\n",
      "for 61_\n",
      "groupideal 1066293\n",
      "groupDigital 439077\n",
      "group 1157022\n",
      "for 66_\n",
      "groupideal 1066293\n",
      "groupDigital 358929\n",
      "group 1120064\n",
      "for 67_\n",
      "groupideal 1066293\n",
      "groupDigital 416911\n",
      "group 1132180\n",
      "for 68_\n",
      "groupideal 1066293\n",
      "groupDigital 298279\n",
      "group 1114458\n",
      "for 81_\n",
      "groupideal 1066293\n",
      "groupDigital 476568\n",
      "group 1160059\n",
      "for 89_\n",
      "groupideal 1066293\n",
      "groupDigital 539302\n",
      "group 1191335\n",
      "for 92_\n",
      "groupideal 1066293\n",
      "groupDigital 357430\n",
      "group 1182442\n",
      "for 93_\n",
      "groupideal 1066293\n",
      "groupDigital 555208\n",
      "group 1168912\n",
      "for 94_\n",
      "groupideal 1066293\n",
      "groupDigital 538957\n",
      "group 1168514\n",
      "for 95_\n",
      "groupideal 1066293\n",
      "groupDigital 535803\n",
      "group 1163114\n"
     ]
    }
   ],
   "source": [
    "number_S_0_ = return_number_sovpad(Slide_,\"\")\n",
    "number_S_57_ = return_number_sovpad(Slide_,\"57_\")\n",
    "number_S_60_ = return_number_sovpad(Slide_,\"60_\")\n",
    "number_S_61_ = return_number_sovpad(Slide_,\"61_\")\n",
    "number_S_66_ = return_number_sovpad(Slide_,\"66_\")\n",
    "number_S_67_ = return_number_sovpad(Slide_,\"67_\")\n",
    "number_S_68_ = return_number_sovpad(Slide_,\"68_\")\n",
    "number_S_81_ = return_number_sovpad(Slide_,\"81_\")\n",
    "number_S_89_ = return_number_sovpad(Slide_,\"89_\")\n",
    "number_S_92_ = return_number_sovpad(Slide_,\"92_\")\n",
    "number_S_93_ = return_number_sovpad(Slide_,\"93_\")\n",
    "number_S_94_ = return_number_sovpad(Slide_,\"94_\")\n",
    "number_S_95_ = return_number_sovpad(Slide_,\"95_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ba16f103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groupideal1066293\n",
      "groupDigital560948\n",
      "group1228118\n"
     ]
    }
   ],
   "source": [
    "number_S_0_ = return_number_sovpad(Slide_,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "84281757",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_S_57_ = return_number_sovpad(Slide_,\"57_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e101fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_S_61_ = return_number_sovpad(Slide_,\"61_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fc252603",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_S_66_ = return_number_sovpad(Slide_,\"66_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f644c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_S_67_ = return_number_sovpad(Slide_,\"67_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4bc45cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_S_68_ = return_number_sovpad(Slide_,\"68_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e81d695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_S_81_ = return_number_sovpad(Slide_,\"81_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4b7750d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_S_89_ = return_number_sovpad(Slide_,\"89_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1051fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_S_92_ = return_number_sovpad(Slide_,\"92_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d49ca3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_S_93_ = return_number_sovpad(Slide_,\"93_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "49793fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_S_94_ = return_number_sovpad(Slide_,\"94_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "763c0b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_S_95_ = return_number_sovpad(Slide_,\"95_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "16d98519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S0 - 399123\n",
      "S57 - 281352\n",
      "S60 - 356377\n",
      "S61 - 348348\n",
      "S66 - 305158\n",
      "S67 - 351024\n",
      "S68 - 250114\n",
      "S81 - 382802\n",
      "S89 - 414260\n",
      "S92 - 241281\n",
      "S93 - 452589\n",
      "S94 - 436736\n",
      "S95 - 438982\n"
     ]
    }
   ],
   "source": [
    "print(\"S0 - \" + str(number_S_0_))\n",
    "print(\"S57 - \" + str(number_S_57_))\n",
    "print(\"S60 - \" + str(number_S_60_))\n",
    "print(\"S61 - \" + str(number_S_61_))\n",
    "print(\"S66 - \" + str(number_S_66_))\n",
    "print(\"S67 - \" + str(number_S_67_))\n",
    "print(\"S68 - \" + str(number_S_68_))\n",
    "print(\"S81 - \" + str(number_S_81_))\n",
    "print(\"S89 - \" + str(number_S_89_))\n",
    "print(\"S92 - \" + str(number_S_92_))\n",
    "print(\"S93 - \" + str(number_S_93_))\n",
    "print(\"S94 - \" + str(number_S_94_))\n",
    "print(\"S95 - \" + str(number_S_95_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "90e71e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 960, 3)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_image= Image.open(\"/Users/alexeyvaganov/doc/files/color_matcher/temp/IMG_2847.jpeg\")\n",
    "my_image = my_image.convert('RGB')\n",
    "my_image_lab = rgb2lab(my_image)\n",
    "my_image_lab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "34e978fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15.07521656, -12.67294754,  18.01043186])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_image_lab[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09e2a45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
