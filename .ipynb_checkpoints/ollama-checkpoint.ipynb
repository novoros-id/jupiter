{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e113d51",
   "metadata": {},
   "source": [
    "https://developers.sber.ru/docs/ru/gigachat/sdk/guides/local-llms?ysclid=lvyap08s4s738058876"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a99c63",
   "metadata": {},
   "source": [
    "ollama run llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c42e24cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d2c4034",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(\n",
    "    model=\"llama3\", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d69a20b",
   "metadata": {},
   "source": [
    "# Пример промта 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30c107ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''\n",
    "Определи, содержит ли сообщение в контексте предложение работы. Если содержит ответь 1, если не содержит ответь 0\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: Содержит ли сообщение предложение работы?\n",
    "\n",
    "Answer: Верни только одно число, без текста\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c559bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05e3c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"Меня всегда интересовал вопрос безопасности\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5db2a24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.format(context=context) # Добавляем сообщение в промпт\n",
    "llm.invoke(prompt) # Ответ модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0699d71",
   "metadata": {},
   "source": [
    "# Пример промта 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e82f29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Это разговор с ИИ-помощником.\n",
    "Помощник обычно опирается на примеры.\n",
    "\n",
    "Examples:\n",
    "A + A = AA\n",
    "B + С = BC\n",
    "2 + 2 = 22\n",
    "\n",
    "User: 1 + 1?\n",
    "AI: \"\"\"\n",
    "\n",
    "print(llm.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8a00af",
   "metadata": {},
   "source": [
    "# Пример промта 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88434778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Москва (Moscow) - это столица Российской Федерации."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Москва (Moscow) - это столица Российской Федерации.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke('''Назови столицу России''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e9a9f",
   "metadata": {},
   "source": [
    "# Пример промта 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "655d5fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gift: True\n",
      "\n",
      "delivery_days: 2\n",
      "\n",
      "price_value: ['Он немного дороже, чем другие но я думаю, что дополнительные функции того стоит.']"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"gift: True\\n\\ndelivery_days: 2\\n\\nprice_value: ['Он немного дороже, чем другие но я думаю, что дополнительные функции того стоит.']\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke('''Из следующего текста извлеки информацию:\n",
    "\n",
    "gift: Был ли товар куплен в подарок кому-то другому?\n",
    "Ответь «True», если да, «False», если нет или неизвестно.\n",
    "\n",
    "delivery_days: Сколько дней потребовалось для доставки товара? \n",
    "Если эта информация не найдена, выведи -1.\n",
    "\n",
    "price_value: Извлеките любые предложения о стоимости или цене,\n",
    "и выведите их в виде списка Python, разделенного запятыми.\n",
    "\n",
    "text: \n",
    "Этот фен для волос просто потрясающий. Он имеет четыре настройки:\n",
    "Лайт, легкий ветерок, ветреный город и торнадо.\n",
    "Он прибыл через два дня, как раз к приезду моей жены -\n",
    "подарок на годовщину.\n",
    "Думаю, моей жене это настолько понравилось, что она потеряла дар речи.\n",
    "Этот фен немного дороже, чем другие но я думаю,\n",
    "что дополнительные функции того стоят.''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
