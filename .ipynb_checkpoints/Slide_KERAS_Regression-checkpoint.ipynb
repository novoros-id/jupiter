{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37c2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageEnhance\n",
    "import numpy as np \n",
    "import os\n",
    "import cv2\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage import color\n",
    "from skimage.io import imsave\n",
    "# np.save('example_1', a)\n",
    "# b = np.load('example/example_1.npy')\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, ReLU\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "#from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import load_model\n",
    "import pandas as pd \n",
    "# import tensorflow as tf\n",
    "# from keras.models import load_model\n",
    "# import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70dd174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_folder = \"/Users/alexeyvaganov/doc/files/color_matcher/type\"\n",
    "image_massiv = \"/Users/alexeyvaganov/doc/files/color_matcher/temp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38942b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e3daec",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "515b5889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img_file):\n",
    "    img = Image.open(img_file)\n",
    "    img.show()\n",
    "# array_transform_nastr = [\n",
    "#     [1,1,0.8],\n",
    "#     [1,1,2]\n",
    "# ]\n",
    "# array_transform_nastr = [\n",
    "#     [1.5,0.5,0.5],\n",
    "#     [1.5,1,0.5],\n",
    "#     [1,1,0.8],\n",
    "#     [1,1,2],\n",
    "#     [2,1.2,0],\n",
    "#     [2,1.2,0.1]\n",
    "# ]\n",
    "\n",
    "array_transform_nastr = [\n",
    "    [1.5,0.5,0.5],\n",
    "    [1.5,1,0.5],\n",
    "    [1,1,2]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d1f2041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(img_pil,brightness,contrast,color):\n",
    "    if (brightness != 0):\n",
    "        enhancer = ImageEnhance.Brightness(img_pil)\n",
    "        img_pil = enhancer.enhance(brightness)\n",
    "    if (contrast != 0):\n",
    "        enhancer = ImageEnhance.Contrast(img_pil)\n",
    "        img_pil = enhancer.enhance(contrast)\n",
    "    if (color != 0):\n",
    "        enhancer = ImageEnhance.Color(img_pil)\n",
    "        img_pil = enhancer.enhance(color) \n",
    "    return img_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de20d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(array_x_y,a,b):\n",
    "    h=0\n",
    "    while h <= a.shape[0]-pixel:\n",
    "        w=0\n",
    "        while w <= a.shape[1]-pixel:\n",
    "            #print (h,\",\",h+56)\n",
    "            array_x_y.append([a[h,w][1],a[h,w][2],b[h,w][1],b[h,w][2]])\n",
    "#             x_ = a[h,w]\n",
    "#             y_ = b[h,w]\n",
    "#             array_x_y.append([x_,y_])\n",
    "            w+=pixel\n",
    "        h+=pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48212e0b",
   "metadata": {},
   "source": [
    "# Из одной папки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b309380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/c02w9bp14k1fx5943h90k0500000gn/T/ipykernel_68677/1632532704.py:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  array_full_image = np.array(array_image)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(54, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_folder = \"/Users/alexeyvaganov/doc/files/color_matcher/slide_X_2\"\n",
    "array_image = []\n",
    "for root, dirs, files in os.walk(image_folder):\n",
    "    for file in files:\n",
    "        if file == \".DS_Store\":\n",
    "            continue\n",
    "        img_pil = Image.open(root + \"/\" + file)\n",
    "        img_pil = img_pil.convert('RGB')\n",
    "        img_pil_lab = rgb2lab(img_pil)\n",
    "        #img_cv2_ish = cv2.imread(root + \"/\" + file)\n",
    "        for x in array_transform_nastr:\n",
    "            img_ = transform_image(img_pil,x[0],x[1],x[2])\n",
    "            #img_.save(\"/Users/alexeyvaganov/doc/files/color_matcher/temp/geeks.jpg\")\n",
    "            #img_cv2_transf = cv2.imread(\"/Users/alexeyvaganov/doc/files/color_matcher/temp/geeks.jpg\")\n",
    "            img_lab = rgb2lab(img_)\n",
    "            #img_pil = rgb2lab(img_pil)\n",
    "            array_image.append([np.array(img_lab),np.array(img_pil_lab)])\n",
    "        \n",
    "array_full_image = np.array(array_image) \n",
    "array_full_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0894c462",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "imsave(\"/Users/alexeyvaganov/doc/files/color_matcher/temp/tttt.jpg\", lab2rgb(array_full_image[0,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50abc6d3",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f690e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "i=0\n",
    "x_sgape = array_full_image.shape[0]\n",
    "while i < x_sgape:\n",
    "    crop_image(data,array_full_image[i,0],array_full_image[i,1])\n",
    "    i+=1\n",
    "\n",
    "dFrame = pd.DataFrame(data) \n",
    "\n",
    "# array_x_y = []\n",
    "# i=0\n",
    "# x_sgape = array_full_image.shape[0]\n",
    "# while i < x_sgape:\n",
    "#     crop_image(array_x_y,array_full_image[i,0],array_full_image[i,1])\n",
    "#     i+=1\n",
    "# array_crop_image = np.array(array_x_y) \n",
    "# array_crop_image = 1.0/255*array_crop_image\n",
    "# array_crop_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5806c69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.228665</td>\n",
       "      <td>1.182758</td>\n",
       "      <td>-4.573750</td>\n",
       "      <td>2.711215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.228665</td>\n",
       "      <td>1.182758</td>\n",
       "      <td>-4.573750</td>\n",
       "      <td>2.711215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.833490</td>\n",
       "      <td>1.623497</td>\n",
       "      <td>-4.894234</td>\n",
       "      <td>2.661258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.828129</td>\n",
       "      <td>1.620235</td>\n",
       "      <td>-4.977653</td>\n",
       "      <td>2.720906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.220202</td>\n",
       "      <td>1.178041</td>\n",
       "      <td>-5.085864</td>\n",
       "      <td>2.798276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52765702</th>\n",
       "      <td>32.252903</td>\n",
       "      <td>-53.570892</td>\n",
       "      <td>13.406327</td>\n",
       "      <td>-30.804071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52765703</th>\n",
       "      <td>32.741895</td>\n",
       "      <td>-53.426798</td>\n",
       "      <td>13.793980</td>\n",
       "      <td>-30.919076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52765704</th>\n",
       "      <td>32.978934</td>\n",
       "      <td>-53.348597</td>\n",
       "      <td>13.984154</td>\n",
       "      <td>-30.982821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52765705</th>\n",
       "      <td>31.460226</td>\n",
       "      <td>-51.603020</td>\n",
       "      <td>13.050610</td>\n",
       "      <td>-29.900243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52765706</th>\n",
       "      <td>31.938916</td>\n",
       "      <td>-51.445559</td>\n",
       "      <td>13.375020</td>\n",
       "      <td>-30.034719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52765707 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0          1          2          3\n",
       "0         -2.228665   1.182758  -4.573750   2.711215\n",
       "1         -2.228665   1.182758  -4.573750   2.711215\n",
       "2         -2.833490   1.623497  -4.894234   2.661258\n",
       "3         -2.828129   1.620235  -4.977653   2.720906\n",
       "4         -2.220202   1.178041  -5.085864   2.798276\n",
       "...             ...        ...        ...        ...\n",
       "52765702  32.252903 -53.570892  13.406327 -30.804071\n",
       "52765703  32.741895 -53.426798  13.793980 -30.919076\n",
       "52765704  32.978934 -53.348597  13.984154 -30.982821\n",
       "52765705  31.460226 -51.603020  13.050610 -29.900243\n",
       "52765706  31.938916 -51.445559  13.375020 -30.034719\n",
       "\n",
       "[52765707 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c84ccc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dFrame_ = dFrame.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61cd92ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001059</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>-0.215369</td>\n",
       "      <td>0.588665</td>\n",
       "      <td>-0.139061</td>\n",
       "      <td>0.378457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>-0.215369</td>\n",
       "      <td>0.588665</td>\n",
       "      <td>0.122438</td>\n",
       "      <td>0.470595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.620613</td>\n",
       "      <td>-0.441352</td>\n",
       "      <td>0.662042</td>\n",
       "      <td>-0.194147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>-0.001059</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.261499</td>\n",
       "      <td>0.092139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22490199</th>\n",
       "      <td>-0.703658</td>\n",
       "      <td>-1.453317</td>\n",
       "      <td>-3.093772</td>\n",
       "      <td>-6.429565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22490200</th>\n",
       "      <td>-0.699564</td>\n",
       "      <td>-1.443880</td>\n",
       "      <td>-3.091510</td>\n",
       "      <td>-6.405489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22490202</th>\n",
       "      <td>-0.297403</td>\n",
       "      <td>-2.555699</td>\n",
       "      <td>-0.854491</td>\n",
       "      <td>-11.174781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22490203</th>\n",
       "      <td>-0.292302</td>\n",
       "      <td>-2.467918</td>\n",
       "      <td>-0.673269</td>\n",
       "      <td>-11.512144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22490206</th>\n",
       "      <td>-0.291185</td>\n",
       "      <td>-2.450675</td>\n",
       "      <td>-0.619631</td>\n",
       "      <td>-10.782802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2472496 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2          3\n",
       "0        -0.001059  0.002007  0.000000   0.000000\n",
       "144      -0.215369  0.588665 -0.139061   0.378457\n",
       "152      -0.215369  0.588665  0.122438   0.470595\n",
       "496       0.620613 -0.441352  0.662042  -0.194147\n",
       "872      -0.001059  0.002007  0.261499   0.092139\n",
       "...            ...       ...       ...        ...\n",
       "22490199 -0.703658 -1.453317 -3.093772  -6.429565\n",
       "22490200 -0.699564 -1.443880 -3.091510  -6.405489\n",
       "22490202 -0.297403 -2.555699 -0.854491 -11.174781\n",
       "22490203 -0.292302 -2.467918 -0.673269 -11.512144\n",
       "22490206 -0.291185 -2.450675 -0.619631 -10.782802\n",
       "\n",
       "[2472496 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dFrame_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73977553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5072759, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_crop_image = np.array(dFrame_) \n",
    "array_crop_image = 1.0/255*array_crop_image\n",
    "array_crop_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ded92458",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = array_crop_image[:,0:2]\n",
    "Y_ = array_crop_image[:,2:4]\n",
    "# X_ = X_[:,1:]\n",
    "# Y_ = Y_[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9a0bfb",
   "metadata": {},
   "source": [
    "# KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afd6b801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 12:13:52.686784: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-31 12:13:52.688099: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# модель 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=2, activation='sigmoid'))\n",
    "model.add(ReLU(1.0))\n",
    "model.add(Dense(50, activation='sigmoid'))\n",
    "model.add(ReLU(1.0))\n",
    "model.add(Dense(25, activation='softmax'))\n",
    "\n",
    "#IMPORTANT PART\n",
    "model.add(Dense(2, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "22b5db6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=2, activation='sigmoid'))\n",
    "model.add(ReLU(1.0))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(ReLU(1.0))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "#IMPORTANT PART\n",
    "model.add(Dense(2, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2106974c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "15851/15853 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9252"
     ]
    }
   ],
   "source": [
    "model.fit(X_,Y_,batch_size=256, epochs=15, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1020d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/Users/alexeyvaganov/doc/files/color_matcher/temp/temp_keras_regression.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96faece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33678159",
   "metadata": {},
   "source": [
    "# Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "989a87a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Obr = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00710414",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_massiv = []\n",
    "#file_name_massiv.append(\"IMG_2837_m.jpeg\")\n",
    "#file_name_massiv.append(\"IMG_2825.jpeg\")\n",
    "file_name_massiv.append(\"IMG_3379.jpeg\")\n",
    "file_name_massiv.append(\"IMG_2915.jpeg\")\n",
    "file_name_massiv.append(\"IMG_2980.jpeg\")\n",
    "file_name_massiv.append(\"IMG_3107.jpeg\")\n",
    "file_name_massiv.append(\"IMG_3323.jpeg\")\n",
    "file_name_massiv.append(\"IMG_3336.jpeg\")\n",
    "file_name_massiv.append(\"IMG_2825.jpeg\")\n",
    "file_name_massiv.append(\"IMG_2769.jpeg\")\n",
    "file_name_massiv.append(\"IMG_2837.jpeg\")\n",
    "file_name_massiv.append(\"IMG_2847.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f316e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_testing_file(file_name):\n",
    "    test_image_path = image_massiv + \"/\" + file_name\n",
    "    img_test = Image.open(test_image_path)\n",
    "    img_test = img_test.convert('RGB')\n",
    "    img_test = rgb2lab(img_test)\n",
    "    return np.array(img_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0db5ead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrive_testing_file = []\n",
    "for name_test_file in file_name_massiv:\n",
    "    arr_ = add_testing_file(name_test_file)\n",
    "    arrive_testing_file.append([name_test_file, arr_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89cb3ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(array_full_img_test):\n",
    "    new_img = np.zeros((array_full_img_test.shape[0], array_full_img_test.shape[1], 3))\n",
    "    data_p = []\n",
    "    h=0\n",
    "    while h <= array_full_img_test.shape[0]-pixel:\n",
    "        w=0\n",
    "        while w <= array_full_img_test.shape[1]-pixel:\n",
    "            data_p.append([array_full_img_test[h,w][1],array_full_img_test[h,w][2]])\n",
    "            w+=pixel\n",
    "        h+=pixel \n",
    "        \n",
    "    x_ = np.array(data_p)\n",
    "    x_ = 1.0/255*x_\n",
    "    #x_ = x_.reshape(1,2)\n",
    "    pred_y = model.predict(x_)\n",
    "    \n",
    "    h=0\n",
    "    i=0\n",
    "    while h <= array_full_img_test.shape[0]-pixel:\n",
    "        w=0\n",
    "        while w <= array_full_img_test.shape[1]-pixel:\n",
    "            new_img[h,w] = [array_full_img_test[h,w][0],pred_y[i][0]*256,pred_y[i][1]*256]\n",
    "            i+=1\n",
    "            w+=pixel\n",
    "        h+=pixel \n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edab28f",
   "metadata": {},
   "source": [
    "# Предсказание здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e102714e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexeyvaganov/doc/files/color_matcher/temp/101_type.h5\n",
      "  101/38400 [..............................] - ETA: 58s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 12:21:59.852814: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38400/38400 [==============================] - 60s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexeyvaganov/doc/files/color_matcher/temp/101_IMG_2825.jpeg\n",
      "38400/38400 [==============================] - 60s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexeyvaganov/doc/files/color_matcher/temp/101_IMG_3379.jpeg\n",
      "38400/38400 [==============================] - 61s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexeyvaganov/doc/files/color_matcher/temp/101_IMG_2915.jpeg\n",
      "38400/38400 [==============================] - 65s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexeyvaganov/doc/files/color_matcher/temp/101_IMG_2980.jpeg\n",
      "38400/38400 [==============================] - 60s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexeyvaganov/doc/files/color_matcher/temp/101_IMG_3107.jpeg\n",
      "38400/38400 [==============================] - 61s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexeyvaganov/doc/files/color_matcher/temp/101_IMG_3323.jpeg\n",
      "33280/33280 [==============================] - 52s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexeyvaganov/doc/files/color_matcher/temp/101_IMG_3336.jpeg\n",
      "38400/38400 [==============================] - 59s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexeyvaganov/doc/files/color_matcher/temp/101_IMG_2825.jpeg\n",
      "38400/38400 [==============================] - 60s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexeyvaganov/doc/files/color_matcher/temp/101_IMG_2769.jpeg\n",
      "38400/38400 [==============================] - 57s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexeyvaganov/doc/files/color_matcher/temp/101_IMG_2837.jpeg\n",
      "38400/38400 [==============================] - 57s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexeyvaganov/doc/files/color_matcher/temp/101_IMG_2847.jpeg\n"
     ]
    }
   ],
   "source": [
    "Obr += 1\n",
    "model_name = image_massiv + \"/\" + str(Obr) + \"_type\" + \".h5\"\n",
    "print(model_name)\n",
    "for m_image in arrive_testing_file:\n",
    "    p_image = predict_image(m_image[1])\n",
    "    image_name = image_massiv + \"/\" + str(Obr) + \"_\" + m_image[0]\n",
    "    print(image_name)\n",
    "    imsave(image_name, lab2rgb(p_image))\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68350147",
   "metadata": {},
   "source": [
    "# Старые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "975fb208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "array_full_img_test = arrive_testing_file[0][1]\n",
    "new_img = np.zeros((array_full_img_test.shape[0], array_full_img_test.shape[1], 3))\n",
    "h=0\n",
    "while h <= array_full_img_test.shape[0]-pixel:\n",
    "    w=0\n",
    "    while w <= array_full_img_test.shape[1]-pixel:\n",
    "        new_img[h,w] = [array_full_img_test[h,w][0],array_full_img_test[h,w][1],array_full_img_test[h,w][2]]\n",
    "        w+=pixel\n",
    "    h+=pixel \n",
    "imsave(\"/Users/alexeyvaganov/doc/files/color_matcher/temp/82_IMG_2837_m22.jpeg\", lab2rgb(new_img))\n",
    "#(color.convert_colorspace(new_img, 'HSV', 'RGB')*255).astype(np.uint8)\n",
    "#(color.convert_colorspace(lab2rgb(new_img), 'HSV', 'RGB')*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cef3ba97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 960, 3)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"IMG_2825.jpeg\"\n",
    "test_image_path = image_massiv + \"/\" + file_name\n",
    "img_test = Image.open(test_image_path)\n",
    "img_test = img_test.convert('RGB')\n",
    "#array_img_test.append(img_test) \n",
    "img_test = rgb2lab(img_test)\n",
    "array_full_img_test = np.array(img_test) \n",
    "array_full_img_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87491633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3fb12e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(image_massiv + \"/\" + str(Obr) + \"type_.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "800cb071",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"/Users/alexeyvaganov/doc/files/color_matcher/temp/temp_keras_regression.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
