{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e113d51",
   "metadata": {},
   "source": [
    "https://developers.sber.ru/docs/ru/gigachat/sdk/guides/local-llms?ysclid=lvyap08s4s738058876"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0dbd43",
   "metadata": {},
   "source": [
    "https://github.com/ai-forever/gigachain/blob/master/docs/docs/use_cases/question_answering/gigachat_qa.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a99c63",
   "metadata": {},
   "source": [
    "ollama run llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee3ed751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /Users/alexeyvaganov/miniforge3/lib/python3.9/site-packages (from pypdf) (4.11.0)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-4.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87d7b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chromadb --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c42e24cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d2c4034",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(\n",
    "    model=\"llama3\", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "816598a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# question = \"Где Маша остановилась в Петербурге?\"\n",
    "# llm.invoke([HumanMessage(content=question)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "625a0a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2010acb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-21 20:49:49--  https://stepik.org/media/attachments/lesson/1084288/The_Daughter_of_The_Commandant.pdf\n",
      "Распознаётся stepik.org (stepik.org)… 178.248.239.111\n",
      "Подключение к stepik.org (stepik.org)|178.248.239.111|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 198595 (194K) [application/pdf]\n",
      "Сохранение в: «The_Daughter_of_The_Commandant.pdf»\n",
      "\n",
      "The_Daughter_of_The 100%[===================>] 193,94K  --.-KB/s    за 0,1s    \n",
      "\n",
      "2024-05-21 20:49:50 (1,48 MB/s) - «The_Daughter_of_The_Commandant.pdf» сохранён [198595/198595]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Для загрузки файла с текстом можно использовать команду\n",
    "!wget https://stepik.org/media/attachments/lesson/1084288/The_Daughter_of_The_Commandant.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49183050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://stepik.org/media/attachments/lesson/1084288/pushkin_questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd7aa8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"The_Daughter_of_The_Commandant.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7574a084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 16\n"
     ]
    }
   ],
   "source": [
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "documents = text_splitter.split_documents(documents)\n",
    "print(f\"Total documents: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f361e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb.config import Settings\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d09bddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Если у вас нет видеокарты, укажите 'device': 'cpu'\n",
    "hf_embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"cointegrated/LaBSE-en-ru\", model_kwargs={\"device\": \"cpu\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cb793f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(\n",
    "    documents,\n",
    "    hf_embeddings_model,\n",
    "    client_settings=Settings(anonymized_telemetry=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa6674bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Какое напутствие дал Петру отец?\"\n",
    "data = db.similarity_search(prompt,k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "160d07a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В ответе на вопрос о напутствии, которое дал Петру отец, мы находим следующую фразу в тексте:\n",
      "\n",
      "«отец велит беречь ему платье снову, а честь смолоду»\n",
      "\n",
      "Таким образом, отец даст Петру напутствие: «беречь платье снову» (хранить чистоту) и «а честь смолоду» (и сохранять честь с молодых лет)."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'В ответе на вопрос о напутствии, которое дал Петру отец, мы находим следующую фразу в тексте:\\n\\n«отец велит беречь ему платье снову, а честь смолоду»\\n\\nТаким образом, отец даст Петру напутствие: «беречь платье снову» (хранить чистоту) и «а честь смолоду» (и сохранять честь с молодых лет).'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = f\"Используя эти данные: {data}. Ответь на этот запрос  на русском языке: {prompt}\"\n",
    "llm.invoke([HumanMessage(content=question)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f906c6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Кого убили раздетой на крыльце?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Где Маша остановилась в Петербурге?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Почему Гринев и Савельич сбились с дороги?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Кто издевался над Машей и морил ее голодом?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Куда приговорили отправить Гринева в ссылку?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Сколько детей было в семье Петра Гринева?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Кто воспитывал Петра Гринева?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Сколько казаков попросил Гринев, чтобы очистит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Как далеко находилась от города Белогорская кр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Как звали дочку коменданта?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Что Петя подарил вожатому?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Какое напутствие дал Петру отец?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Кого Пугачев оставил комендантом Белогорской к...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Почему Швабрина перевели в крепость?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Кого просил пощадить Савельич у Пугачева?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question\n",
       "0                     Кого убили раздетой на крыльце?\n",
       "1                 Где Маша остановилась в Петербурге?\n",
       "2          Почему Гринев и Савельич сбились с дороги?\n",
       "3         Кто издевался над Машей и морил ее голодом?\n",
       "4        Куда приговорили отправить Гринева в ссылку?\n",
       "5           Сколько детей было в семье Петра Гринева?\n",
       "6                       Кто воспитывал Петра Гринева?\n",
       "7   Сколько казаков попросил Гринев, чтобы очистит...\n",
       "8   Как далеко находилась от города Белогорская кр...\n",
       "9                         Как звали дочку коменданта?\n",
       "10                         Что Петя подарил вожатому?\n",
       "11                   Какое напутствие дал Петру отец?\n",
       "12  Кого Пугачев оставил комендантом Белогорской к...\n",
       "13               Почему Швабрина перевели в крепость?\n",
       "14          Кого просил пощадить Савельич у Пугачева?"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "310b59c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ec4523ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.Client()\n",
    "collection = client.create_collection(name=\"dogm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "08b2229b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# store each document in a vector embedding database\n",
    "for i, d in enumerate(documents):\n",
    "    response = ollama.embeddings(model=\"nomic-embed-text\", prompt=d.page_content)\n",
    "    embedding = response[\"embedding\"]\n",
    "    print(str(i))\n",
    "    collection.add(\n",
    "        ids=[str(i)],\n",
    "        embeddings=[embedding],\n",
    "        documents=[d.page_content]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f27e7c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example prompt\n",
    "prompt = \"Сколько детей было в семье Петра Гринева?\"\n",
    "\n",
    "# generate an embedding for the prompt and retrieve the most relevant doc\n",
    "response = ollama.embeddings(\n",
    "  prompt=prompt,\n",
    "  model=\"nomic-embed-text\"\n",
    ")\n",
    "results = collection.query(\n",
    "  query_embeddings=[response[\"embedding\"]],\n",
    "    n_results=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2b974a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = results['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "065eb652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В данных текста не упоминается о детях в семье Петра Гринева. Поэтому ответом будет \"нет\" или \"не упоминалось\"."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'В данных текста не упоминается о детях в семье Петра Гринева. Поэтому ответом будет \"нет\" или \"не упоминалось\".'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an example prompt\n",
    "prompt = \"Сколько детей было в семье Петра Гринева?\"\n",
    "\n",
    "# generate an embedding for the prompt and retrieve the most relevant doc\n",
    "response = ollama.embeddings(\n",
    "  prompt=prompt,\n",
    "  model=\"nomic-embed-text\"\n",
    ")\n",
    "results = collection.query(\n",
    "  query_embeddings=[response[\"embedding\"]],\n",
    "    n_results=4\n",
    ")\n",
    "data = results['documents']\n",
    "question = f\"Используя эти данные: {data}. Ответь на этот запрос  на русском языке: {prompt}\"\n",
    "llm.invoke([HumanMessage(content=question)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "332e3b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гринев и Савельич сбились с дороги из-за бурана."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Гринев и Савельич сбились с дороги из-за бурана.'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = f\"Используя эти данные: {data}. Ответь на этот запрос  на русском языке: {prompt}\"\n",
    "llm.invoke([HumanMessage(content=question)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "381592f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Маша остановилась в Царском Селе.\n"
     ]
    }
   ],
   "source": [
    "# generate a response combining the prompt and data we retrieved in step 2\n",
    "output = ollama.generate(\n",
    "  model=\"llama3\",\n",
    "  prompt=f\"Используя эти данные: {data}. Ответь на этот запрос  на русском языке: {prompt}\"\n",
    ")\n",
    "\n",
    "print(output['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fc70e8",
   "metadata": {},
   "source": [
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b91d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48cc1ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_basic(word: str) -> str:\n",
    "    \"\"\"Отвечает на вопрос, кто ты, что ты умеешь, как ты мне можешь помочь, ответ на приветствие\"\"\" # добавляем docstring\n",
    "    return \"Я помощник 1С\"\n",
    "\n",
    "@tool\n",
    "def get_agreement(word: str) -> str:\n",
    "    \"\"\"Отвечает по информации по договорам и если пользователь спрашивает что-то конкретное про договора, например, текст договора, часть договора\"\"\" # добавляем docstring\n",
    "    return \"Вот информация по договорам\"\n",
    "\n",
    "@tool\n",
    "def get_number_agreement(word: str) -> str:\n",
    "    \"\"\"Отвечает про количество договоров, сколько договоров в базе, показать номер договоров\"\"\" # добавляем docstring\n",
    "    return \"Номера заключенных договоров 1,2,3\"\n",
    "\n",
    "tools = [get_basic, get_agreement, get_number_agreement]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b79999c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aece12f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "I'm ready to help!\n",
      "\n",
      "Thought: The user wants to see the payment conditions for agreement number 1. I need to use the `get_agreement` tool to provide this information.\n",
      "\n",
      "Action: get_agreement\n",
      "Action Input: \"Покажи условия платежа по договору 1\u001b[32;1m\u001b[1;3mI'm ready to help!\n",
      "\n",
      "Thought: The user wants to see the payment conditions for agreement number 1. I need to use the `get_agreement` tool to provide this information.\n",
      "\n",
      "Action: get_agreement\n",
      "Action Input: \"Покажи условия платежа по договору 1\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mВот информация по договорам\u001b[0m\n",
      "Thought:Thought: Now that I've used the `get_agreement` action, I need to process the result to extract the payment conditions for agreement number 1.\n",
      "Action: get_agreement\n",
      "Action Input: \"payment conditions\u001b[32;1m\u001b[1;3mThought: Now that I've used the `get_agreement` action, I need to process the result to extract the payment conditions for agreement number 1.\n",
      "Action: get_agreement\n",
      "Action Input: \"payment conditions\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mВот информация по договорам\u001b[0m\n",
      "Thought:Let's go through this step by step.\n",
      "\n",
      "Question: покажи условия платежа по договору 1\n",
      "Thought: I'm ready to help!\n",
      "\n",
      "Thought: The user wants to see the payment conditions for agreement number 1. I need to use the `get_agreement` tool to provide this information.\n",
      "\n",
      "Action: get_agreement\n",
      "Action Input: \"Покажи условия платежа по договору 1\u001b[32;1m\u001b[1;3mLet's go through this step by step.\n",
      "\n",
      "Question: покажи условия платежа по договору 1\n",
      "Thought: I'm ready to help!\n",
      "\n",
      "Thought: The user wants to see the payment conditions for agreement number 1. I need to use the `get_agreement` tool to provide this information.\n",
      "\n",
      "Action: get_agreement\n",
      "Action Input: \"Покажи условия платежа по договору 1\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mВот информация по договорам\u001b[0m\n",
      "Thought:Let's continue!\n",
      "\n",
      "Thought: Now that I've used the `get_agreement` action, I need to process the result to extract the payment conditions for agreement number 1.\n",
      "\n",
      "Action: None (processing the result)\n",
      "\n",
      "Thought: The observation shows that there is more information available. I can use this information to provide the final answer.\n",
      "\n",
      "Final Answer: Вот информация по договорам\n",
      "\n",
      "Note: Since `get_agreement` returns a string, I assume that it contains the payment conditions for agreement number 1. Therefore, my final answer is just a copy of the observation.\u001b[32;1m\u001b[1;3mLet's continue!\n",
      "\n",
      "Thought: Now that I've used the `get_agreement` action, I need to process the result to extract the payment conditions for agreement number 1.\n",
      "\n",
      "Action: None (processing the result)\n",
      "\n",
      "Thought: The observation shows that there is more information available. I can use this information to provide the final answer.\n",
      "\n",
      "Final Answer: Вот информация по договорам\n",
      "\n",
      "Note: Since `get_agreement` returns a string, I assume that it contains the payment conditions for agreement number 1. Therefore, my final answer is just a copy of the observation.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'покажи условия платежа по договору 1',\n",
       " 'output': 'Вот информация по договорам\\n\\nNote: Since `get_agreement` returns a string, I assume that it contains the payment conditions for agreement number 1. Therefore, my final answer is just a copy of the observation.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"покажи условия платежа по договору 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d69a20b",
   "metadata": {},
   "source": [
    "# Пример промта 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30c107ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''\n",
    "Определи, содержит ли сообщение в контексте предложение работы. Если содержит ответь 1, если не содержит ответь 0\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: Содержит ли сообщение предложение работы?\n",
    "\n",
    "Answer: Верни только одно число, без текста\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c559bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05e3c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"Меня всегда интересовал вопрос безопасности\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5db2a24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.format(context=context) # Добавляем сообщение в промпт\n",
    "llm.invoke(prompt) # Ответ модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0699d71",
   "metadata": {},
   "source": [
    "# Пример промта 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e82f29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Это разговор с ИИ-помощником.\n",
    "Помощник обычно опирается на примеры.\n",
    "\n",
    "Examples:\n",
    "A + A = AA\n",
    "B + С = BC\n",
    "2 + 2 = 22\n",
    "\n",
    "User: 1 + 1?\n",
    "AI: \"\"\"\n",
    "\n",
    "print(llm.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8a00af",
   "metadata": {},
   "source": [
    "# Пример промта 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88434778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Столица России - Москва (Moscow)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Столица России - Москва (Moscow)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke('''Назови столицу России''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e9a9f",
   "metadata": {},
   "source": [
    "# Пример промта 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "655d5fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the extracted information:\n",
      "\n",
      "* gift: True (the product was given as a gift to someone else)\n",
      "* delivery_days: 2 (it took 2 days for the product to be delivered)\n",
      "* price_value: ['Он немного дороже, чем другие'] (any mentions of cost or price)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Here is the extracted information:\\n\\n* gift: True (the product was given as a gift to someone else)\\n* delivery_days: 2 (it took 2 days for the product to be delivered)\\n* price_value: ['Он немного дороже, чем другие'] (any mentions of cost or price)\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke('''Из следующего текста извлеки информацию:\n",
    "\n",
    "gift: Был ли товар куплен в подарок кому-то другому?\n",
    "Ответь «True», если да, «False», если нет или неизвестно.\n",
    "\n",
    "delivery_days: Сколько дней потребовалось для доставки товара? \n",
    "Если эта информация не найдена, выведи -1.\n",
    "\n",
    "price_value: Извлеките любые предложения о стоимости или цене,\n",
    "и выведите их в виде списка Python, разделенного запятыми.\n",
    "\n",
    "text: \n",
    "Этот фен для волос просто потрясающий. Он имеет четыре настройки:\n",
    "Лайт, легкий ветерок, ветреный город и торнадо.\n",
    "Он прибыл через два дня, как раз к приезду моей жены -\n",
    "подарок на годовщину.\n",
    "Думаю, моей жене это настолько понравилось, что она потеряла дар речи.\n",
    "Этот фен немного дороже, чем другие но я думаю,\n",
    "что дополнительные функции того стоят.''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
